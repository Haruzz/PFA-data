{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PFA case prediction of crime category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "sf_data = pd.read_csv('C:/Users/harun/Desktop/PFAcase/sf_data.csv', sep=';')\n",
    "sf_districts = pd.read_csv('C:/Users/harun/Desktop/PFAcase/sf_districts.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>weekday</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>resolution</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>label</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assault</td>\n",
       "      <td>false imprisonment</td>\n",
       "      <td>saturday</td>\n",
       "      <td>03/24/2018</td>\n",
       "      <td>07:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.419053</td>\n",
       "      <td>37.758632</td>\n",
       "      <td>violent</td>\n",
       "      <td>mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-criminal</td>\n",
       "      <td>lost property</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>07/19/2017</td>\n",
       "      <td>12:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.419672</td>\n",
       "      <td>37.765050</td>\n",
       "      <td>other</td>\n",
       "      <td>mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-criminal</td>\n",
       "      <td>aided case, mental disturbed</td>\n",
       "      <td>friday</td>\n",
       "      <td>10/13/2017</td>\n",
       "      <td>06:45</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.416894</td>\n",
       "      <td>37.784286</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft from locked auto</td>\n",
       "      <td>sunday</td>\n",
       "      <td>04/22/2018</td>\n",
       "      <td>18:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.420691</td>\n",
       "      <td>37.781483</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft of property</td>\n",
       "      <td>sunday</td>\n",
       "      <td>08/21/2016</td>\n",
       "      <td>10:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.417885</td>\n",
       "      <td>37.785438</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft shoplifting</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>02/24/2016</td>\n",
       "      <td>12:36</td>\n",
       "      <td>arrest, booked</td>\n",
       "      <td>-122.406521</td>\n",
       "      <td>37.785063</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vandalism</td>\n",
       "      <td>malicious mischief, vandalism</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>09/13/2017</td>\n",
       "      <td>10:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.417145</td>\n",
       "      <td>37.712150</td>\n",
       "      <td>other</td>\n",
       "      <td>sunnydale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>suspicious occ</td>\n",
       "      <td>suspicious occurrence</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>08/15/2017</td>\n",
       "      <td>12:23</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.409011</td>\n",
       "      <td>37.781134</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                    description    weekday        date  \\\n",
       "0         assault             false imprisonment   saturday  03/24/2018   \n",
       "1    non-criminal                  lost property  wednesday  07/19/2017   \n",
       "2    non-criminal   aided case, mental disturbed     friday  10/13/2017   \n",
       "3   larceny/theft   petty theft from locked auto     sunday  04/22/2018   \n",
       "4   larceny/theft        petty theft of property     sunday  08/21/2016   \n",
       "5   larceny/theft        petty theft shoplifting  wednesday  02/24/2016   \n",
       "6       vandalism  malicious mischief, vandalism  wednesday  09/13/2017   \n",
       "7  suspicious occ          suspicious occurrence    tuesday  08/15/2017   \n",
       "\n",
       "    time      resolution   longitude   latitude    label    district  \n",
       "0  07:00            none -122.419053  37.758632  violent     mission  \n",
       "1  12:00            none -122.419672  37.765050    other     mission  \n",
       "2  06:45            none -122.416894  37.784286    other  tenderloin  \n",
       "3  18:00            none -122.420691  37.781483    other  tenderloin  \n",
       "4  10:00            none -122.417885  37.785438    other  tenderloin  \n",
       "5  12:36  arrest, booked -122.406521  37.785063    other  tenderloin  \n",
       "6  10:00            none -122.417145  37.712150    other   sunnydale  \n",
       "7  12:23            none -122.409011  37.781134    other  tenderloin  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge on ID\n",
    "df = pd.merge(sf_data, sf_districts, on='id')\n",
    "df = df.drop(columns=['id'])\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 592854 entries, 0 to 592853\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   category     592854 non-null  object \n",
      " 1   description  592854 non-null  object \n",
      " 2   weekday      592854 non-null  object \n",
      " 3   date         592854 non-null  object \n",
      " 4   time         592854 non-null  object \n",
      " 5   resolution   592854 non-null  object \n",
      " 6   longitude    592854 non-null  float64\n",
      " 7   latitude     592854 non-null  float64\n",
      " 8   label        592854 non-null  object \n",
      " 9   district     592854 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 45.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about dataset\n",
    "\n",
    "- 592,854 instances of recorded crimes\n",
    "- 10 columns (8-9 features, 1 target which is either label or category)\n",
    "- I would like to know the category, and use the label as a feature. However, it could also have been the other way around for more simplicity.\n",
    "- no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Data cleaning\n",
    "- Feature Engineering\n",
    "- Feature encoding (done after the train-test-split to avoid data leakage)\n",
    "    - Integer encode / label encode ordinal categorical features \n",
    "    - One hot encode nominal categorical features (weekday, district, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to python datetimes and make columns for year, month, day, hour and minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>weekday</th>\n",
       "      <th>resolution</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>label</th>\n",
       "      <th>district</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assault</td>\n",
       "      <td>false imprisonment</td>\n",
       "      <td>saturday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.419053</td>\n",
       "      <td>37.758632</td>\n",
       "      <td>violent</td>\n",
       "      <td>mission</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-criminal</td>\n",
       "      <td>lost property</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.419672</td>\n",
       "      <td>37.765050</td>\n",
       "      <td>other</td>\n",
       "      <td>mission</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-criminal</td>\n",
       "      <td>aided case, mental disturbed</td>\n",
       "      <td>friday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.416894</td>\n",
       "      <td>37.784286</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft from locked auto</td>\n",
       "      <td>sunday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.420691</td>\n",
       "      <td>37.781483</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft of property</td>\n",
       "      <td>sunday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.417885</td>\n",
       "      <td>37.785438</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft shoplifting</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>arrest, booked</td>\n",
       "      <td>-122.406521</td>\n",
       "      <td>37.785063</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vandalism</td>\n",
       "      <td>malicious mischief, vandalism</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.417145</td>\n",
       "      <td>37.712150</td>\n",
       "      <td>other</td>\n",
       "      <td>sunnydale</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>suspicious occ</td>\n",
       "      <td>suspicious occurrence</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.409011</td>\n",
       "      <td>37.781134</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                    description    weekday      resolution  \\\n",
       "0         assault             false imprisonment   saturday            none   \n",
       "1    non-criminal                  lost property  wednesday            none   \n",
       "2    non-criminal   aided case, mental disturbed     friday            none   \n",
       "3   larceny/theft   petty theft from locked auto     sunday            none   \n",
       "4   larceny/theft        petty theft of property     sunday            none   \n",
       "5   larceny/theft        petty theft shoplifting  wednesday  arrest, booked   \n",
       "6       vandalism  malicious mischief, vandalism  wednesday            none   \n",
       "7  suspicious occ          suspicious occurrence    tuesday            none   \n",
       "\n",
       "    longitude   latitude    label    district  year  month  day  hour  minute  \n",
       "0 -122.419053  37.758632  violent     mission  2018      3   24     7       0  \n",
       "1 -122.419672  37.765050    other     mission  2017      7   19    12       0  \n",
       "2 -122.416894  37.784286    other  tenderloin  2017     10   13     6      45  \n",
       "3 -122.420691  37.781483    other  tenderloin  2018      4   22    18       0  \n",
       "4 -122.417885  37.785438    other  tenderloin  2016      8   21    10       0  \n",
       "5 -122.406521  37.785063    other  tenderloin  2016      2   24    12      36  \n",
       "6 -122.417145  37.712150    other   sunnydale  2017      9   13    10       0  \n",
       "7 -122.409011  37.781134    other  tenderloin  2017      8   15    12      23  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the date into python datetime\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n",
    "\n",
    "# Create a new columns for the year, month and day\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "# Convert the 'time' column to just time data (feature)\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M').dt.time\n",
    "\n",
    "# convert 'time' back to datetime to extract the hour\n",
    "df['hour'] = pd.to_datetime(df['time'].astype(str), format='%H:%M:%S').dt.hour\n",
    "df['minute'] = pd.to_datetime(df['time'].astype(str), format='%H:%M:%S').dt.minute\n",
    "\n",
    "# drop date since we have already extracted the year, month and day\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# drop time since we have already extracted the hour and minute\n",
    "df.drop('time', axis=1, inplace=True)\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "# Split into training and a temporary set (combining validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.isnull().sum())\n",
    "# print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of nominal features and label encoding of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# List of nominal features (excluding the target variable 'category')\n",
    "nominal_features = ['district', 'resolution', 'weekday', 'label']\n",
    "\n",
    "# Apply OneHotEncoder to X_train and transform X_test\n",
    "X_train_ohe = ohe.fit_transform(X_train[nominal_features])\n",
    "X_test_ohe = ohe.transform(X_test[nominal_features])\n",
    "X_val_ohe = ohe.transform(X_val[nominal_features])\n",
    "\n",
    "# Reset the index of X_train and X_test\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert the sparse matrices to dense arrays and then to DataFrames\n",
    "X_train_ohe_df = pd.DataFrame(X_train_ohe.toarray(), columns=ohe.get_feature_names_out(nominal_features))\n",
    "X_test_ohe_df = pd.DataFrame(X_test_ohe.toarray(), columns=ohe.get_feature_names_out(nominal_features))\n",
    "X_val_ohe_df = pd.DataFrame(X_val_ohe.toarray(), columns=ohe.get_feature_names_out(nominal_features))\n",
    "\n",
    "# Drop the original nominal features from X_train and X_test\n",
    "X_train = X_train.drop(columns=nominal_features)\n",
    "X_test = X_test.drop(columns=nominal_features)\n",
    "X_val = X_val.drop(columns=nominal_features)\n",
    "\n",
    "# Concatenate the new one-hot encoded features with X_train and X_test\n",
    "X_train = pd.concat([X_train, X_train_ohe_df], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_ohe_df], axis=1)\n",
    "X_val = pd.concat([X_val, X_val_ohe_df], axis=1)\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply the LabelEncoder to the 'category' column\n",
    "# Fit the encoder on the y_train data and transform y_train\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Transform y_test data using the same encoder\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# aswell for validation\n",
    "y_val_encoded = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arson': 0, 'assault': 1, 'bad checks': 2, 'bribery': 3, 'burglary': 4, 'disorderly conduct': 5, 'driving under the influence': 6, 'drug/narcotic': 7, 'drunkenness': 8, 'embezzlement': 9, 'extortion': 10, 'forgery/counterfeiting': 11, 'fraud': 12, 'gambling': 13, 'kidnapping': 14, 'larceny/theft': 15, 'liquor laws': 16, 'loitering': 17, 'missing person': 18, 'non-criminal': 19, 'other offenses': 20, 'pornography/obscene mat': 21, 'prostitution': 22, 'recovered vehicle': 23, 'robbery': 24, 'secondary codes': 25, 'sex offenses, forcible': 26, 'sex offenses, non forcible': 27, 'stolen property': 28, 'suicide': 29, 'suspicious occ': 30, 'trespass': 31, 'vandalism': 32, 'vehicle theft': 33, 'warrants': 34, 'weapon laws': 35}\n"
     ]
    }
   ],
   "source": [
    "# mapping of categories\n",
    "category_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any null value in the training and testing sets\n",
    "# X_train.isnull().sum()\n",
    "# X_test.isnull().sum()\n",
    "# y_train.isnull().sum()\n",
    "# y_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n",
    "\n",
    "In this section, I apply the TF-IDF  vectorization to the 'description' column of our dataset. \n",
    "\n",
    "1. **Initialization of TfidfVectorizer**: I set up the TF-IDF vectorizer with specific parameters to control the complexity of the resulting feature space. These parameters include:\n",
    "    - `stop_words='english'`: Removes common English words that are unlikely to have predictive power.\n",
    "    - `max_features=100`: Limits the number of features to the top 100 words by term frequency across the corpus, helping to reduce model complexity and potential overfitting.\n",
    "    - `min_df=5`: Excludes words that appear in fewer than 5 crimes, thus focusing on more relevant terms.\n",
    "    - `max_df=0.5`: Ignores terms that appear in more than 50% of the crimes, as these terms are too common and unlikely to be useful for differentiation.\n",
    "\n",
    "2. **Fitting and Transforming Data**: We fit the vectorizer to the 'description' column of the training data and then transform both the training and test datasets. This conversion results in a matrix of TF-IDF features for each dataset.\n",
    "\n",
    "3. **Creating DataFrames from Matrices**: The sparse matrices obtained from the transformation are converted to dense arrays and then into DataFrames. These DataFrames are subsequently used in the model training and evaluation process.\n",
    "\n",
    "By applying TF-IDF, I aim to capture the most significant linguistic patterns in the 'description' data, which should enhance the predictive quality of our model while avoiding overfitting through controlled feature selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to use TF-idf instead since I dont  want a large number of features, some of which might be contributing to overfitting.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=100, min_df=5, max_df=0.5)\n",
    "\n",
    "# Fit the TfidfVectorizer on the 'description' column of the training data and transform it\n",
    "X_train_description_tfidf = tfidf.fit_transform(X_train['description']).toarray()\n",
    "\n",
    "# Transform the 'description' column of the test data\n",
    "X_test_description_tfidf = tfidf.transform(X_test['description']).toarray()\n",
    "\n",
    "X_val_description_tfidf = tfidf.transform(X_val['description']).toarray()\n",
    "\n",
    "# Generate column names for the bag of words features\n",
    "tfidf_feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Create DataFrames with the bag of words features for training and testing sets\n",
    "X_train_description_tfidf_df = pd.DataFrame(X_train_description_tfidf, columns=tfidf_feature_names)\n",
    "X_test_description_tfidf_df = pd.DataFrame(X_test_description_tfidf, columns=tfidf_feature_names)\n",
    "X_val_description_tfidf_df = pd.DataFrame(X_val_description_tfidf, columns=tfidf_feature_names)\n",
    "\n",
    "# Drop the original 'description' column from training and testing sets\n",
    "X_train = X_train.drop('description', axis=1)\n",
    "X_test = X_test.drop('description', axis=1)\n",
    "X_val = X_val.drop('description', axis=1)\n",
    "\n",
    "# Concatenate the new bag of words features with the original training and testing sets\n",
    "X_train = pd.concat([X_train, X_train_description_tfidf_df], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_description_tfidf_df], axis=1)\n",
    "X_val = pd.concat([X_val, X_val_description_tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>district_mission</th>\n",
       "      <th>district_sunnydale</th>\n",
       "      <th>district_tenderloin</th>\n",
       "      <th>...</th>\n",
       "      <th>trespassing</th>\n",
       "      <th>unlawful</th>\n",
       "      <th>use</th>\n",
       "      <th>vandalism</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>vehicles</th>\n",
       "      <th>violation</th>\n",
       "      <th>violence</th>\n",
       "      <th>warrant</th>\n",
       "      <th>weapon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.418474</td>\n",
       "      <td>37.712104</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.408421</td>\n",
       "      <td>37.783570</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.411988</td>\n",
       "      <td>37.785023</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.412414</td>\n",
       "      <td>37.783004</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.407546</td>\n",
       "      <td>37.784401</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-122.410792</td>\n",
       "      <td>37.783695</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-122.421058</td>\n",
       "      <td>37.766599</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-122.412899</td>\n",
       "      <td>37.785097</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    longitude   latitude  year  month  day  hour  minute  district_mission  \\\n",
       "0 -122.418474  37.712104  2004      9   27    18      50               0.0   \n",
       "1 -122.408421  37.783570  2016      3    5    15      50               0.0   \n",
       "2 -122.411988  37.785023  2013      3   17    13      45               0.0   \n",
       "3 -122.412414  37.783004  2003      5   13    13       7               0.0   \n",
       "4 -122.407546  37.784401  2008      9   17    16       0               0.0   \n",
       "5 -122.410792  37.783695  2014      4    8     9      10               0.0   \n",
       "6 -122.421058  37.766599  2016     11    2     8      30               1.0   \n",
       "7 -122.412899  37.785097  2009      8   28     2      25               0.0   \n",
       "\n",
       "   district_sunnydale  district_tenderloin  ...  trespassing  unlawful  \\\n",
       "0                 1.0                  0.0  ...          0.0       0.0   \n",
       "1                 0.0                  1.0  ...          0.0       0.0   \n",
       "2                 0.0                  1.0  ...          0.0       0.0   \n",
       "3                 0.0                  1.0  ...          0.0       0.0   \n",
       "4                 0.0                  1.0  ...          0.0       0.0   \n",
       "5                 0.0                  1.0  ...          0.0       0.0   \n",
       "6                 0.0                  0.0  ...          0.0       0.0   \n",
       "7                 0.0                  1.0  ...          0.0       0.0   \n",
       "\n",
       "       use  vandalism  vehicle  vehicles  violation  violence  warrant  weapon  \n",
       "0  0.00000        0.0      0.0       0.0        0.0       0.0      0.0     0.0  \n",
       "1  0.00000        0.0      0.0       0.0        0.0       0.0      0.0     0.0  \n",
       "2  0.00000        0.0      0.0       0.0        0.0       0.0      0.0     0.0  \n",
       "3  0.00000        0.0      0.0       0.0        0.0       0.0      0.0     1.0  \n",
       "4  0.71985        0.0      0.0       0.0        0.0       0.0      0.0     0.0  \n",
       "5  0.00000        0.0      0.0       0.0        0.0       0.0      0.0     0.0  \n",
       "6  0.00000        0.0      0.0       0.0        0.0       0.0      0.0     0.0  \n",
       "7  0.00000        0.0      0.0       0.0        0.0       0.0      0.0     1.0  \n",
       "\n",
       "[8 rows x 133 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training:\n",
    "   - Train a classification model.\n",
    "   - I will explore different algorithms such as LogRes, RFC, KNN,, DecisionTree and XGBoost to find the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "        LogisticRegression(max_iter=200, random_state=42, solver='liblinear'),\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Validation Accuracy: 0.9620396218299584\n",
      "LogisticRegression Test Accuracy: 0.9618119101635307\n",
      "RandomForestClassifier Validation Accuracy: 0.9738300258916599\n",
      "RandomForestClassifier Test Accuracy: 0.973526410336423\n",
      "KNeighborsClassifier Validation Accuracy: 0.41726897808064367\n",
      "KNeighborsClassifier Test Accuracy: 0.41834006628939624\n",
      "DecisionTreeClassifier Validation Accuracy: 0.9655818033077228\n",
      "DecisionTreeClassifier Test Accuracy: 0.9658685513321132\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "     # Get the name of the classifier\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    val_pred = classifier.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val_encoded, val_pred)\n",
    "    print(f\"{classifier_name} Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_pred = classifier.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test_encoded, test_pred)\n",
    "    print(f\"{classifier_name} Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation accuracy: 0.9688709718227897\n",
      "XGBoost Test accuracy: 0.9683818134282413\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=50, \n",
    "    objective=\"multi:softprob\",\n",
    "    learning_rate=0.05,\n",
    "    gamma=1,\n",
    "    max_depth=5,\n",
    "    min_child_weight=6,\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=1.0,\n",
    "    subsample=0.33,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=1, \n",
    "    n_jobs=4)\n",
    "\n",
    "xgb.fit(X_train, y_train_encoded)\n",
    "\n",
    "# evaluate on val set\n",
    "y_val_pred = xgb.predict(X_val)\n",
    "print(\"XGBoost Validation accuracy:\", accuracy_score(y_val_encoded, y_val_pred))\n",
    "\n",
    "# evaluate on test set\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "print(\"XGBoost Test accuracy:\", accuracy_score(y_test_encoded, y_test_pred))\n",
    "\n",
    "# print(accuracy_score(y_test_encoded, xgb.predict(X_test)))\n",
    "# # # print(classification_report(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might be the possibility of overfitting which I will continuously investigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finding best hyperparameters. Might take a long time to run, therefore, it is commented out\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define your XGBClassifier\n",
    "# xgb = XGBClassifier(random_state=1, n_jobs=4)\n",
    "\n",
    "# # Define the grid of hyperparameters to search\n",
    "# param_grid = {\n",
    "#     'learning_rate': (0.1, 0.2),\n",
    "#     'min_child_weight': (0, 10),\n",
    "#     'max_depth': (1, 100),\n",
    "#     'max_delta_step': (0, 20),\n",
    "#     'subsample': (0.01, 1.0),\n",
    "#     'min_child_weight': (0, 5),\n",
    "#     'n_estimators': (50, 100),\n",
    "# }\n",
    "\n",
    "# # Setup the grid search\n",
    "# grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, n_jobs=2, verbose=2)\n",
    "\n",
    "# # Perform the grid search on your data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and score\n",
    "# best_parameters = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print(\"Best Parameters:\", best_parameters)\n",
    "# print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96781131 0.96750207 0.96848556 0.96830283 0.96855585]\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Now use cross_val_score with the preprocessed data\n",
    "scores = cross_val_score(xgb, X_train, y_train_encoded, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.9681315248000255\n"
     ]
    }
   ],
   "source": [
    "print(\"Average cross-validation score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation: 0.000\n"
     ]
    }
   ],
   "source": [
    "print('Standard Deviation: %.3f' % (scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
