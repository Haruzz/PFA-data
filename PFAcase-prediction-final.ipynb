{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PFA case prediction of crime category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "sf_data = pd.read_csv('C:/Users/harun/Desktop/PFAcase/sf_data.csv', sep=';')\n",
    "sf_districts = pd.read_csv('C:/Users/harun/Desktop/PFAcase/sf_districts.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>weekday</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>resolution</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>label</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assault</td>\n",
       "      <td>false imprisonment</td>\n",
       "      <td>saturday</td>\n",
       "      <td>03/24/2018</td>\n",
       "      <td>07:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.419053</td>\n",
       "      <td>37.758632</td>\n",
       "      <td>violent</td>\n",
       "      <td>mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-criminal</td>\n",
       "      <td>lost property</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>07/19/2017</td>\n",
       "      <td>12:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.419672</td>\n",
       "      <td>37.765050</td>\n",
       "      <td>other</td>\n",
       "      <td>mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-criminal</td>\n",
       "      <td>aided case, mental disturbed</td>\n",
       "      <td>friday</td>\n",
       "      <td>10/13/2017</td>\n",
       "      <td>06:45</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.416894</td>\n",
       "      <td>37.784286</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft from locked auto</td>\n",
       "      <td>sunday</td>\n",
       "      <td>04/22/2018</td>\n",
       "      <td>18:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.420691</td>\n",
       "      <td>37.781483</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft of property</td>\n",
       "      <td>sunday</td>\n",
       "      <td>08/21/2016</td>\n",
       "      <td>10:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.417885</td>\n",
       "      <td>37.785438</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft shoplifting</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>02/24/2016</td>\n",
       "      <td>12:36</td>\n",
       "      <td>arrest, booked</td>\n",
       "      <td>-122.406521</td>\n",
       "      <td>37.785063</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vandalism</td>\n",
       "      <td>malicious mischief, vandalism</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>09/13/2017</td>\n",
       "      <td>10:00</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.417145</td>\n",
       "      <td>37.712150</td>\n",
       "      <td>other</td>\n",
       "      <td>sunnydale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>suspicious occ</td>\n",
       "      <td>suspicious occurrence</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>08/15/2017</td>\n",
       "      <td>12:23</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.409011</td>\n",
       "      <td>37.781134</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                    description    weekday        date  \\\n",
       "0         assault             false imprisonment   saturday  03/24/2018   \n",
       "1    non-criminal                  lost property  wednesday  07/19/2017   \n",
       "2    non-criminal   aided case, mental disturbed     friday  10/13/2017   \n",
       "3   larceny/theft   petty theft from locked auto     sunday  04/22/2018   \n",
       "4   larceny/theft        petty theft of property     sunday  08/21/2016   \n",
       "5   larceny/theft        petty theft shoplifting  wednesday  02/24/2016   \n",
       "6       vandalism  malicious mischief, vandalism  wednesday  09/13/2017   \n",
       "7  suspicious occ          suspicious occurrence    tuesday  08/15/2017   \n",
       "\n",
       "    time      resolution   longitude   latitude    label    district  \n",
       "0  07:00            none -122.419053  37.758632  violent     mission  \n",
       "1  12:00            none -122.419672  37.765050    other     mission  \n",
       "2  06:45            none -122.416894  37.784286    other  tenderloin  \n",
       "3  18:00            none -122.420691  37.781483    other  tenderloin  \n",
       "4  10:00            none -122.417885  37.785438    other  tenderloin  \n",
       "5  12:36  arrest, booked -122.406521  37.785063    other  tenderloin  \n",
       "6  10:00            none -122.417145  37.712150    other   sunnydale  \n",
       "7  12:23            none -122.409011  37.781134    other  tenderloin  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge on ID\n",
    "df = pd.merge(sf_data, sf_districts, on='id')\n",
    "df = df.drop(columns=['id'])\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 592854 entries, 0 to 592853\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   category     592854 non-null  object \n",
      " 1   description  592854 non-null  object \n",
      " 2   weekday      592854 non-null  object \n",
      " 3   date         592854 non-null  object \n",
      " 4   time         592854 non-null  object \n",
      " 5   resolution   592854 non-null  object \n",
      " 6   longitude    592854 non-null  float64\n",
      " 7   latitude     592854 non-null  float64\n",
      " 8   label        592854 non-null  object \n",
      " 9   district     592854 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 45.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about dataset\n",
    "\n",
    "- 592,854 instances of recorded crimes\n",
    "- 10 columns (8-9 features, 1 target which is either label or category)\n",
    "- I would like to know the category, and use the label as a feature. However, it could also have been the other way around for more simplicity.\n",
    "- no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Data cleaning\n",
    "- Feature Engineering\n",
    "- Feature encoding (done after the train-test-split to avoid data leakage)\n",
    "    - Integer encode / label encode ordinal categorical features \n",
    "    - One hot encode nominal categorical features (weekday, district, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to python datetimes and make columns for year, month, day, hour and minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>weekday</th>\n",
       "      <th>resolution</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>label</th>\n",
       "      <th>district</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assault</td>\n",
       "      <td>false imprisonment</td>\n",
       "      <td>saturday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.419053</td>\n",
       "      <td>37.758632</td>\n",
       "      <td>violent</td>\n",
       "      <td>mission</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-criminal</td>\n",
       "      <td>lost property</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.419672</td>\n",
       "      <td>37.765050</td>\n",
       "      <td>other</td>\n",
       "      <td>mission</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-criminal</td>\n",
       "      <td>aided case, mental disturbed</td>\n",
       "      <td>friday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.416894</td>\n",
       "      <td>37.784286</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft from locked auto</td>\n",
       "      <td>sunday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.420691</td>\n",
       "      <td>37.781483</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft of property</td>\n",
       "      <td>sunday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.417885</td>\n",
       "      <td>37.785438</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>larceny/theft</td>\n",
       "      <td>petty theft shoplifting</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>arrest, booked</td>\n",
       "      <td>-122.406521</td>\n",
       "      <td>37.785063</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vandalism</td>\n",
       "      <td>malicious mischief, vandalism</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.417145</td>\n",
       "      <td>37.712150</td>\n",
       "      <td>other</td>\n",
       "      <td>sunnydale</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>suspicious occ</td>\n",
       "      <td>suspicious occurrence</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>none</td>\n",
       "      <td>-122.409011</td>\n",
       "      <td>37.781134</td>\n",
       "      <td>other</td>\n",
       "      <td>tenderloin</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                    description    weekday      resolution  \\\n",
       "0         assault             false imprisonment   saturday            none   \n",
       "1    non-criminal                  lost property  wednesday            none   \n",
       "2    non-criminal   aided case, mental disturbed     friday            none   \n",
       "3   larceny/theft   petty theft from locked auto     sunday            none   \n",
       "4   larceny/theft        petty theft of property     sunday            none   \n",
       "5   larceny/theft        petty theft shoplifting  wednesday  arrest, booked   \n",
       "6       vandalism  malicious mischief, vandalism  wednesday            none   \n",
       "7  suspicious occ          suspicious occurrence    tuesday            none   \n",
       "\n",
       "    longitude   latitude    label    district  year  month  day  hour  minute  \n",
       "0 -122.419053  37.758632  violent     mission  2018      3   24     7       0  \n",
       "1 -122.419672  37.765050    other     mission  2017      7   19    12       0  \n",
       "2 -122.416894  37.784286    other  tenderloin  2017     10   13     6      45  \n",
       "3 -122.420691  37.781483    other  tenderloin  2018      4   22    18       0  \n",
       "4 -122.417885  37.785438    other  tenderloin  2016      8   21    10       0  \n",
       "5 -122.406521  37.785063    other  tenderloin  2016      2   24    12      36  \n",
       "6 -122.417145  37.712150    other   sunnydale  2017      9   13    10       0  \n",
       "7 -122.409011  37.781134    other  tenderloin  2017      8   15    12      23  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the date into python datetime\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n",
    "\n",
    "# Create a new columns for the year, month and day\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "# Convert the 'time' column to just time data (feature)\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M').dt.time\n",
    "\n",
    "# convert 'time' back to datetime to extract the hour\n",
    "df['hour'] = pd.to_datetime(df['time'].astype(str), format='%H:%M:%S').dt.hour\n",
    "df['minute'] = pd.to_datetime(df['time'].astype(str), format='%H:%M:%S').dt.minute\n",
    "\n",
    "# drop date since we have already extracted the year, month and day\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# drop time since we have already extracted the hour and minute\n",
    "df.drop('time', axis=1, inplace=True)\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.isnull().sum())\n",
    "# print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of nominal features and label encoding of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# List of nominal features (excluding the target variable 'category')\n",
    "nominal_features = ['district', 'resolution', 'weekday', 'label']\n",
    "\n",
    "# Apply OneHotEncoder to X_train and transform X_test\n",
    "X_train_ohe = ohe.fit_transform(X_train[nominal_features])\n",
    "X_test_ohe = ohe.transform(X_test[nominal_features])\n",
    "\n",
    "# Reset the index of X_train and X_test\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert the sparse matrices to dense arrays and then to DataFrames\n",
    "X_train_ohe_df = pd.DataFrame(X_train_ohe.toarray(), columns=ohe.get_feature_names_out(nominal_features))\n",
    "X_test_ohe_df = pd.DataFrame(X_test_ohe.toarray(), columns=ohe.get_feature_names_out(nominal_features))\n",
    "\n",
    "# Drop the original nominal features from X_train and X_test\n",
    "X_train = X_train.drop(columns=nominal_features)\n",
    "X_test = X_test.drop(columns=nominal_features)\n",
    "\n",
    "# Concatenate the new one-hot encoded features with X_train and X_test\n",
    "X_train = pd.concat([X_train, X_train_ohe_df], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_ohe_df], axis=1)\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply the LabelEncoder to the 'category' column\n",
    "# Fit the encoder on the y_train data and transform y_train\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Transform y_test data using the same encoder\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arson': 0,\n",
       " 'assault': 1,\n",
       " 'bad checks': 2,\n",
       " 'bribery': 3,\n",
       " 'burglary': 4,\n",
       " 'disorderly conduct': 5,\n",
       " 'driving under the influence': 6,\n",
       " 'drug/narcotic': 7,\n",
       " 'drunkenness': 8,\n",
       " 'embezzlement': 9,\n",
       " 'extortion': 10,\n",
       " 'forgery/counterfeiting': 11,\n",
       " 'fraud': 12,\n",
       " 'gambling': 13,\n",
       " 'kidnapping': 14,\n",
       " 'larceny/theft': 15,\n",
       " 'liquor laws': 16,\n",
       " 'loitering': 17,\n",
       " 'missing person': 18,\n",
       " 'non-criminal': 19,\n",
       " 'other offenses': 20,\n",
       " 'pornography/obscene mat': 21,\n",
       " 'prostitution': 22,\n",
       " 'recovered vehicle': 23,\n",
       " 'robbery': 24,\n",
       " 'secondary codes': 25,\n",
       " 'sex offenses, forcible': 26,\n",
       " 'sex offenses, non forcible': 27,\n",
       " 'stolen property': 28,\n",
       " 'suicide': 29,\n",
       " 'suspicious occ': 30,\n",
       " 'trespass': 31,\n",
       " 'vandalism': 32,\n",
       " 'vehicle theft': 33,\n",
       " 'warrants': 34,\n",
       " 'weapon laws': 35}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping of categories\n",
    "category_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "category_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any null value in the training and testing sets\n",
    "# X_train.isnull().sum()\n",
    "# X_test.isnull().sum()\n",
    "# y_train.isnull().sum()\n",
    "# y_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorization:\n",
    "   - Using scikit-learn's `CountVectorizer`, we'll convert the preprocessed text data into a matrix of token counts.\n",
    "   - Each row in the matrix represents a document, and each column represents a unique token.\n",
    "   - The cell value denotes the frequency of the token in the corresponding document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the CountVectorizer on the 'description' column of the training data and transform it\n",
    "X_train_description = cv.fit_transform(X_train['description']).toarray()\n",
    "\n",
    "# Transform the 'description' column of the test data\n",
    "X_test_description = cv.transform(X_test['description']).toarray()\n",
    "\n",
    "# Generate column names for the bag of words features\n",
    "bow_feature_names = cv.get_feature_names_out()\n",
    "\n",
    "# Create DataFrames with the bag of words features for training and testing sets\n",
    "X_train_description_df = pd.DataFrame(X_train_description, columns=bow_feature_names)\n",
    "X_test_description_df = pd.DataFrame(X_test_description, columns=bow_feature_names)\n",
    "\n",
    "# Drop the original 'description' column from training and testing sets\n",
    "X_train = X_train.drop('description', axis=1)\n",
    "X_test = X_test.drop('description', axis=1)\n",
    "\n",
    "# Concatenate the new bag of words features with the original training and testing sets\n",
    "X_train = pd.concat([X_train, X_train_description_df], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_description_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training:\n",
    "   - Train a classification model.\n",
    "   - I will explore different algorithms such as RFC, KNN, AdaBoost, DecisionTree and XGBoost to find the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "classifiers = [\n",
    "        # RandomForestClassifier(),\n",
    "        # KNeighborsClassifier(),\n",
    "        # AdaBoostClassifier(algorithm='SAMME'),\n",
    "        # DecisionTreeClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in classifiers:\n",
    "    model = classifier\n",
    "    model.fit(X_train, y_train_encoded)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classifier)\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    print(accuracy_score(y_test_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996980711978477\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100, \n",
    "    objective=\"multi:softprob\",\n",
    "    learning_rate=0.05,\n",
    "    gamma=1,\n",
    "    max_depth=10,\n",
    "    min_child_weight=6,\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=1.0,\n",
    "    subsample=0.33,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=1, \n",
    "    n_jobs=4)\n",
    "\n",
    "xgb.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(accuracy_score(y_test_encoded, xgb.predict(X_test)))\n",
    "# # print(classification_report(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be some overfitting which I will investigate beforehand and fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finding best hyperparameters. Might take a long time to run, therefore, it is commented out\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define your XGBClassifier\n",
    "# xgb = XGBClassifier(random_state=1, n_jobs=4)\n",
    "\n",
    "# # Define the grid of hyperparameters to search\n",
    "# param_grid = {\n",
    "#     'learning_rate': (0.1, 0.2),\n",
    "#     'min_child_weight': (0, 10),\n",
    "#     'max_depth': (1, 100),\n",
    "#     'max_delta_step': (0, 20),\n",
    "#     'subsample': (0.01, 1.0),\n",
    "#     'min_child_weight': (0, 5),\n",
    "#     'n_estimators': (50, 100),\n",
    "# }\n",
    "\n",
    "# # Setup the grid search\n",
    "# grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, n_jobs=2, verbose=2)\n",
    "\n",
    "# # Perform the grid search on your data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and score\n",
    "# best_parameters = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print(\"Best Parameters:\", best_parameters)\n",
    "# print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out for now because it takes a long time to run\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # Now use cross_val_score with the preprocessed data\n",
    "# scores = cross_val_score(xgb, X_train, y_train_encoded, cv=5, scoring='accuracy')\n",
    "# print(\"Cross-validation scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_accuracy = scores.mean()\n",
    "# print('Mean Accuracy: %.3f' % (mean_accuracy))\n",
    "# print('Standard Deviation: %.3f' % (scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
